{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "\n",
    "\n",
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://127.0.0.1:27017/'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.beard_db\n",
    "collection = db.awards\n",
    "\n",
    "#check to see if insert many worked\n",
    "documents = db.awards.find()\n",
    "test_list =[]\n",
    "for document in documents:\n",
    "    test_list.append(document)\n",
    "db_awards_df = pd.DataFrame(test_list)\n",
    "\n",
    "# #This module takes all of our winning persons and randomly selects 100 unique authors for analysis. \n",
    "# import random\n",
    "\n",
    "# winners_unique = db_awards_df.loc[db_awards_df['achievement status'] == \"Winner\",['honoree name']].value_counts()\n",
    "\n",
    "# winner_list = []\n",
    "# while len(winner_list) < 100:\n",
    "#     random_index = random.randint(0,len(winners_unique)-1)\n",
    "#     winner = winners_unique.index[random_index][0]\n",
    "#     if winner in winner_list:\n",
    "#         continue\n",
    "#     else:\n",
    "#         winner_list.append(winner)\n",
    "\n",
    "\n",
    "# pd.DataFrame(winner_list).to_csv(\"C:/Users/JoshWeidenaar/Documents/Bootcamp/1_Homework/Project-2/listof100.csv\")\n",
    "\n",
    "db_awards_df[\"api_name\"] = [i.split(\"/\")[-1].replace(\"_\",\"%20\") for i in db_awards_df['wiki_url']]\n",
    "\n",
    "honoree_names = db_awards_df['api_name'].value_counts().index.tolist()\n",
    "\n",
    "# Wikiscrape Module\n",
    "\n",
    "\n",
    "listie_dicts = []\n",
    "for i in honoree_names:\n",
    "\n",
    "    WikiMedia_URL = f\"https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&ppprop=wikibase_item&titles={i}&formatversion=2&format=json\"\n",
    "    response = requests.get(WikiMedia_URL).json()\n",
    "    id_for_both = response['query']['pages'][0]\n",
    "    missing_key = 'missing'\n",
    "    found_key = 'pageprops'\n",
    "    honoree_dict = {}\n",
    "    honoree_dict['name'] = i\n",
    "    if found_key in id_for_both.keys():\n",
    "        found_ID = id_for_both['pageprops']['wikibase_item']\n",
    "        honoree_dict['id'] = found_ID\n",
    "    elif missing_key in id_for_both.keys():\n",
    "        missing_ID = id_for_both['missing']\n",
    "        honoree_dict['id'] = missing_ID\n",
    "    else: \n",
    "        print(f\"somethings wrong with {i}\")\n",
    "    listie_dicts.append(honoree_dict)\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(listie_dicts).loc[pd.DataFrame(listie_dicts)['id'] != True,]\n",
    "\n",
    "df = df.loc[pd.notna(df['id']),]\n",
    "\n",
    "Sex_ID = \"P21\"\n",
    "gender_possibilities = { \"Q6581072\" : 'Female',\n",
    " \"Q6581097\" : 'Male',\n",
    " \"Q1097630\" : 'Intersex',\n",
    " 'Q1052281' : 'Transgender_Female',\n",
    " 'Q2449503' : 'Transgender_Male'}\n",
    "\n",
    "input_possibilities = list(gender_possibilities.values())\n",
    "\n",
    "nums = [input_possibilities.index(i) for i in input_possibilities]\n",
    "\n",
    "text_forinput = \"0 == Female\\n\\n 1 == Male\\n\\n 2 == Intersex\\n\\n 3 == Transgender_Female\\n\\n 4 == Transgender_Male\"\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "author_gender_list = []\n",
    "for idx, i in enumerate(df['id']):\n",
    "    print(f\"author: {df['name'][idx]} \\n{(idx/len(df))*100}% of the way there\\n\\n\")\n",
    "    WikiData_URL = f\"https://m.wikidata.org/wiki/Special:EntityData/{i}.json\"\n",
    "    response = requests.get(WikiData_URL).json()\n",
    "    try:\n",
    "        property_verification = response['entities'][i]['claims'][Sex_ID][0]['mainsnak']['property']\n",
    "        gender_found = response['entities'][i]['claims'][Sex_ID][0]['mainsnak']['datavalue']['value']['id']\n",
    "\n",
    "        if gender_found in gender_possibilities.keys():\n",
    "            gender_found = gender_possibilities[gender_found]\n",
    "        else:\n",
    "            gender_found = \"NOTFOUND\"\n",
    "        author_gender_list.append(gender_found)\n",
    "    except KeyError:\n",
    "        print(f\"{i} prompted a KeyError \\n please enter gender assumed gender of {df['name'][idx]}\\n\\n\\n{text_forinput} \")\n",
    "        author_gender_list.append(input_possibilities[int(input())])\n",
    "\n",
    "    \n",
    "\n",
    "#change Jack Turner to MALE\n",
    "df['gender'] = author_gender_list\n",
    "\n",
    "df['matchname'] = [i.replace('%20',\" \") for i in df['name']]\n",
    "\n",
    "df_final = pd.merge(db_awards_df,df,how='left',left_on='honoree name',right_on='matchname')\n",
    "\n",
    "len(df_final.loc[pd.notnull(df_final['gender']),'honoree name'].value_counts())\n",
    "\n",
    "df_final.drop(axis=1,labels=['api_name','name','matchname','index'],inplace=True)\n",
    "\n",
    "df_final.to_json('Beard_db_final.json', default_handler=str,orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
