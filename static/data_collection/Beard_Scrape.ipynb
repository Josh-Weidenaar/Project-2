{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By just looking, I know that 1991-2020 are the years of beard data that is available on their website (2021 doesn't have anything because the awards were cancelled)\n",
    "length = 2021-1991\n",
    "years = [i+1991 for i in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After manually reviewing the data fields returned on the beard website, and the order in which they occur\n",
    "cols_simple = [\"honoree name\",\"blank\",\"Award Category\",\"name of work/effort\",\"location of effort/who foot the bill\",\"type of work\",\"achievement status\",\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOT THIS GREAT CODE SNIPPET FROM https://stackoverflow.com/questions/11553721/using-a-string-variable-as-a-variable-name\n",
    "#IT'S VERY SIMPLE, BUT IT BLEW MY MIND. ANYWAYS I USE IT BELOW\n",
    "    #my_data = {}\n",
    "    #foo = \"hello\"\n",
    "    #my_data[foo] = \"goodbye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 1991\n",
      "on 2 of 2\n",
      "on 1992\n",
      "on 2 of 2\n",
      "on 1993\n",
      "on 2 of 2\n",
      "on 1994\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 1995\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 1996\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 1997\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 1998\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 1999\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2000\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2001\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2002\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2003\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2004\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2005\n",
      "on 2 of 3\n",
      "on 3 of 3\n",
      "on 2006\n",
      "on 2 of 4\n",
      "on 3 of 4\n",
      "on 4 of 4\n",
      "on 2007\n",
      "on 2 of 4\n",
      "on 3 of 4\n",
      "on 4 of 4\n",
      "on 2008\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2009\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2010\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2011\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2012\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2013\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2014\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2015\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2016\n",
      "on 2 of 8\n",
      "on 3 of 8\n",
      "on 4 of 8\n",
      "on 5 of 8\n",
      "on 6 of 8\n",
      "on 7 of 8\n",
      "on 8 of 8\n",
      "on 2017\n",
      "on 2 of 8\n",
      "on 3 of 8\n",
      "on 4 of 8\n",
      "on 5 of 8\n",
      "on 6 of 8\n",
      "on 7 of 8\n",
      "on 8 of 8\n",
      "on 2018\n",
      "on 2 of 8\n",
      "on 3 of 8\n",
      "on 4 of 8\n",
      "on 5 of 8\n",
      "on 6 of 8\n",
      "on 7 of 8\n",
      "on 8 of 8\n",
      "on 2019\n",
      "on 2 of 7\n",
      "on 3 of 7\n",
      "on 4 of 7\n",
      "on 5 of 7\n",
      "on 6 of 7\n",
      "on 7 of 7\n",
      "on 2020\n",
      "on 2 of 8\n",
      "on 3 of 8\n",
      "on 4 of 8\n",
      "on 5 of 8\n",
      "on 6 of 8\n",
      "on 7 of 8\n",
      "on 8 of 8\n"
     ]
    }
   ],
   "source": [
    "listie_dicts = []\n",
    "for year in years:\n",
    "    \n",
    "    #first loop iterates through the years of beard data available, it reads through the first page by calling 'page = 1' below\n",
    "    #we then save all awards as a bs4 result set by targetting the attribute \"data-award-template\" in the \"div\" tag\n",
    "    #in order to account for pagination, we target the second to last \"li\" tag with the 'page-item' class to determine the # of pages\n",
    "    #needing to be scraped.\n",
    "    page = 1\n",
    "    \n",
    "    #lets user know where parsing is at\n",
    "    print(f\"on {year}\")\n",
    "    url = f'https://www.jamesbeard.org/awards/search?keyword=&year={year}&page={page}'\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    awarding = soup.find_all(attrs={\"data-award-template\":'components.search-results.award.book.book'})\n",
    "    pages = soup.find_all(\"li\",class_='page-item')[-2].get_text()\n",
    "    \n",
    "    #we then parse through our bs4 result set and narrow all the way down to single data points on single awards\n",
    "    #this parses only through the first page\n",
    "    for i in awarding:\n",
    "        \n",
    "        #'p' tags are where all of the awards are stored            \n",
    "        plop = i.find_all('p')\n",
    "        \n",
    "        #initialize the dictionary for the individual award information to be stored\n",
    "        award = {}\n",
    "        \n",
    "        #obtain the data-award-template value that is only available in the 'div' tag\n",
    "        uid = i.get('data-award-template')\n",
    "        \n",
    "        #establish data quality fields\n",
    "        award['award_type'] = uid\n",
    "        award['length'] = len(plop)\n",
    "        award['pagenum'] = 1\n",
    "        \n",
    "        for count, j in enumerate(plop):\n",
    "            \n",
    "            key = cols_simple[count]\n",
    "            award[key] = j.text.strip()\n",
    "            \n",
    "        listie_dicts.append(award)\n",
    "   \n",
    "    #This then takes the page length information gathered from the first scrape and scrapes and parses through the exact same way through all\n",
    "    #pages for that year of award data.\n",
    "    for page in range(2,int(pages)+1):\n",
    "        \n",
    "        #lets user know where parsing is at\n",
    "        print(f\"on {page} of {int(pages)}\")\n",
    "        \n",
    "        url = f'https://www.jamesbeard.org/awards/search?keyword=&year={year}&page={page}'\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        awarding = soup.find_all(attrs={\"data-award-template\":'components.search-results.award.book.book'})\n",
    "        \n",
    "        for i in awarding:\n",
    "            \n",
    "            #'p' tags are where all of the awards are stored\n",
    "            plop = i.find_all('p')\n",
    "            \n",
    "            #initialize the dictionary for the individual award information to be stored\n",
    "            award = {}\n",
    "            \n",
    "            #obtain the data-award-template value that is only available in the 'div' tag\n",
    "            uid = i.get('data-award-template')\n",
    "            \n",
    "            #establish data quality fields\n",
    "            award['award_type'] = uid\n",
    "            award['length'] = len(plop)\n",
    "            award['pagenum'] = page\n",
    "            \n",
    "            for count, j in enumerate(plop):\n",
    "                \n",
    "                #cols_simple are the attribute names I wanted data points stored as... they were originally made to be agnostic to award-type\n",
    "                #but the current scraper grabs only one data-award-template (planning to implement scraper of all types with code blocks at end of ipynb)\n",
    "                key = cols_simple[count]\n",
    "                award[key] = j.text.strip()\n",
    "                \n",
    "            listie_dicts.append(award)\n",
    "            \n",
    "#after all of the years and pages have been scraped and parsed, it is saved into a dataframe for further cleaning\n",
    "df = pd.DataFrame(listie_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save for backup\n",
    "df.to_csv('Beard_Book_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, 'Book', 'Winner', '1991'],\n",
       "       [nan, 'Book', 'Winner', '1992'],\n",
       "       [nan, 'Book', 'Winner', '1992'],\n",
       "       [nan, 'Book', 'Winner', '1993'],\n",
       "       [nan, 'Book', 'Winner', '1993'],\n",
       "       [nan, 'Book', 'Winner', '1994'],\n",
       "       [nan, 'Book', 'Winner', '1995'],\n",
       "       [nan, 'Book', 'Winner', '1996'],\n",
       "       [nan, 'Book', 'Winner', '1997'],\n",
       "       [nan, 'Book', 'Winner', '1998'],\n",
       "       [nan, 'Book', 'Winner', '1999'],\n",
       "       [nan, 'Book', 'Winner', '2000'],\n",
       "       [nan, 'Book', 'Winner', '2001'],\n",
       "       [nan, 'Book', 'Winner', '2002'],\n",
       "       [nan, 'Book', 'Winner', '2003'],\n",
       "       [nan, 'Book', 'Winner', '2004'],\n",
       "       [nan, 'Book', 'Winner', '2005'],\n",
       "       [nan, 'Book', 'Winner', '2006'],\n",
       "       [nan, 'Book', 'Winner', '2007'],\n",
       "       [nan, 'Book', 'Winner', '2008'],\n",
       "       [nan, 'Book', 'Winner', '2009'],\n",
       "       [nan, 'Book', 'Winner', '2010'],\n",
       "       [nan, 'Book', 'Winner', '2011'],\n",
       "       [nan, 'Book', 'Winner', '2012'],\n",
       "       [nan, 'Book', 'Winner', '2013'],\n",
       "       [nan, 'Book', 'Winner', '2014'],\n",
       "       [nan, 'Book', 'Winner', '2015'],\n",
       "       [nan, 'Book', 'Winner', '2016'],\n",
       "       [nan, 'Book', 'Winner', '2017'],\n",
       "       [nan, 'Book', 'Winner', '2018'],\n",
       "       [nan, 'Book', 'Winner', '2019'],\n",
       "       [nan, 'Book', 'Winner', '2020']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes the awards with 7 fields and inserts nan's where the field is missing according to user review, this will put all fields in the correct columns for len = 7 awards\n",
    "\n",
    "## THIS IS TO BE RUN ONE TIME, IF IT IS RUN MORE THAN ONCE, IT MUST THEN BE RUN UNTIL THE ARRAYS BEGIN WITH nan according to what is printed in insert\n",
    "\n",
    "insert = df.loc[df['length'] == 7, 'location of effort/who foot the bill':'year'].values\n",
    "\n",
    "for count, i in enumerate(insert):\n",
    "    val = i[3]\n",
    "    i[3] = i[2]\n",
    "    i[2] = i[1]\n",
    "    i[1] = i[0]\n",
    "    i[0] = val    \n",
    "df.loc[df['length'] ==7, df.columns[7:11]] = insert\n",
    "\n",
    "insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after all len 7 awards have been corrected, we will now change their length to 8\n",
    "df.loc[df['length'] == 7, 'length'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceed\n"
     ]
    }
   ],
   "source": [
    "#as data continues to be uploaded and new awards are given, there may be other length book fields (this is also in preparation for building out award scraping beyond just book awards)\n",
    "# this will let user know whether or not there may be additional data transformations needed to the data frame.\n",
    "if len(df['length'].value_counts()) <= 1:\n",
    "    print(\"proceed\")\n",
    "else:\n",
    "    print(\"addition transformations need to be made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_type</th>\n",
       "      <th>length</th>\n",
       "      <th>pagenum</th>\n",
       "      <th>honoree name</th>\n",
       "      <th>Award Category</th>\n",
       "      <th>name of work/effort</th>\n",
       "      <th>location of effort/who foot the bill</th>\n",
       "      <th>type of work</th>\n",
       "      <th>achievement status</th>\n",
       "      <th>year</th>\n",
       "      <th>wiki_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The Editors of Better Homes &amp; Gardens</td>\n",
       "      <td>Baking &amp; Desserts</td>\n",
       "      <td>Old Fashioned Home Baking</td>\n",
       "      <td>(Meredith Corporation)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>1991</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Editors_of_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The Editors of Sunset Magazine</td>\n",
       "      <td>Health and Diet</td>\n",
       "      <td>Light &amp; Healthy Cook Book</td>\n",
       "      <td>(Sunset Publishing Corporation)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>1991</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Editors_of_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The Moosewood Collective</td>\n",
       "      <td>Fruits, Vegetables &amp; Grains</td>\n",
       "      <td>Sundays at Moosewood Restaurant</td>\n",
       "      <td>(Fireside/Simon &amp; Schuster)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>1991</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Moosewood_Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Burton Anderson</td>\n",
       "      <td>Wine &amp; Spirits</td>\n",
       "      <td>The Wine Atlas of Italy: A Traveler's Guide to...</td>\n",
       "      <td>(Simon &amp; Schuster)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Winner</td>\n",
       "      <td>1991</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Burton_Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Jean Anderson</td>\n",
       "      <td>Techniques</td>\n",
       "      <td>Microways</td>\n",
       "      <td>(Doubleday)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>1991</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jean_Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Editors at America's Test Kitchen</td>\n",
       "      <td>Vegetable-Focused Cooking</td>\n",
       "      <td>Vegetables Illustrated</td>\n",
       "      <td>(America's Test Kitchen)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Editors_at_Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Kaitlyn Goalen</td>\n",
       "      <td>American</td>\n",
       "      <td>Cook Like a Local</td>\n",
       "      <td>(Clarkson Potter)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kaitlyn_Goalen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Jancis Robinson</td>\n",
       "      <td>Cookbook Hall of Fame</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Book</td>\n",
       "      <td>Winner</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jancis_Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Abra Berens</td>\n",
       "      <td>Vegetable-Focused Cooking</td>\n",
       "      <td>Ruffage</td>\n",
       "      <td>(Chronicle Books)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abra_Berens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>components.search-results.award.book.book</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Kwame Onwuachi</td>\n",
       "      <td>Writing</td>\n",
       "      <td>Notes from a Young Black Chef</td>\n",
       "      <td>(Knopf)</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nominee</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kwame_Onwuachi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1431 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     award_type  length  pagenum  \\\n",
       "0     components.search-results.award.book.book       8        1   \n",
       "1     components.search-results.award.book.book       8        1   \n",
       "2     components.search-results.award.book.book       8        1   \n",
       "3     components.search-results.award.book.book       8        1   \n",
       "4     components.search-results.award.book.book       8        1   \n",
       "...                                         ...     ...      ...   \n",
       "1426  components.search-results.award.book.book       8        2   \n",
       "1427  components.search-results.award.book.book       8        4   \n",
       "1428  components.search-results.award.book.book       8        4   \n",
       "1429  components.search-results.award.book.book       8        4   \n",
       "1430  components.search-results.award.book.book       8        4   \n",
       "\n",
       "                               honoree name               Award Category  \\\n",
       "0     The Editors of Better Homes & Gardens            Baking & Desserts   \n",
       "1            The Editors of Sunset Magazine              Health and Diet   \n",
       "2                  The Moosewood Collective  Fruits, Vegetables & Grains   \n",
       "3                           Burton Anderson               Wine & Spirits   \n",
       "4                             Jean Anderson                   Techniques   \n",
       "...                                     ...                          ...   \n",
       "1426      Editors at America's Test Kitchen    Vegetable-Focused Cooking   \n",
       "1427                         Kaitlyn Goalen                     American   \n",
       "1428                        Jancis Robinson        Cookbook Hall of Fame   \n",
       "1429                            Abra Berens    Vegetable-Focused Cooking   \n",
       "1430                         Kwame Onwuachi                      Writing   \n",
       "\n",
       "                                    name of work/effort  \\\n",
       "0                             Old Fashioned Home Baking   \n",
       "1                             Light & Healthy Cook Book   \n",
       "2                       Sundays at Moosewood Restaurant   \n",
       "3     The Wine Atlas of Italy: A Traveler's Guide to...   \n",
       "4                                             Microways   \n",
       "...                                                 ...   \n",
       "1426                             Vegetables Illustrated   \n",
       "1427                                  Cook Like a Local   \n",
       "1428                                                      \n",
       "1429                                            Ruffage   \n",
       "1430                      Notes from a Young Black Chef   \n",
       "\n",
       "     location of effort/who foot the bill type of work achievement status  \\\n",
       "0                  (Meredith Corporation)         Book            Nominee   \n",
       "1         (Sunset Publishing Corporation)         Book            Nominee   \n",
       "2             (Fireside/Simon & Schuster)         Book            Nominee   \n",
       "3                      (Simon & Schuster)         Book             Winner   \n",
       "4                             (Doubleday)         Book            Nominee   \n",
       "...                                   ...          ...                ...   \n",
       "1426             (America's Test Kitchen)         Book            Nominee   \n",
       "1427                    (Clarkson Potter)         Book            Nominee   \n",
       "1428                                  NaN         Book             Winner   \n",
       "1429                    (Chronicle Books)         Book            Nominee   \n",
       "1430                              (Knopf)         Book            Nominee   \n",
       "\n",
       "      year                                           wiki_url  \n",
       "0     1991  https://en.wikipedia.org/wiki/The_Editors_of_B...  \n",
       "1     1991  https://en.wikipedia.org/wiki/The_Editors_of_S...  \n",
       "2     1991  https://en.wikipedia.org/wiki/The_Moosewood_Co...  \n",
       "3     1991      https://en.wikipedia.org/wiki/Burton_Anderson  \n",
       "4     1991        https://en.wikipedia.org/wiki/Jean_Anderson  \n",
       "...    ...                                                ...  \n",
       "1426  2020  https://en.wikipedia.org/wiki/Editors_at_Ameri...  \n",
       "1427  2020       https://en.wikipedia.org/wiki/Kaitlyn_Goalen  \n",
       "1428  2020      https://en.wikipedia.org/wiki/Jancis_Robinson  \n",
       "1429  2020          https://en.wikipedia.org/wiki/Abra_Berens  \n",
       "1430  2020       https://en.wikipedia.org/wiki/Kwame_Onwuachi  \n",
       "\n",
       "[1431 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for future implementation of wiki api integration\n",
    "df['wiki_name'] = df['honoree name'].str.replace(' ', '_')\n",
    "df['wiki_url'] = [f\"https://en.wikipedia.org/wiki/{i}\" for i in df['wiki_name'] ]\n",
    "df.drop(labels=['wiki_name','blank'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://127.0.0.1:27017/'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.beard_db\n",
    "collection = db.awards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all stored information & upload via df (this should be updated with an index rule so when it is queried, only new records are entered into the database, and no old records are deleted)\n",
    "collection.delete_many({})\n",
    "collection.insert_many(df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://127.0.0.1:27017/'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.beard_db\n",
    "collection = db.awards\n",
    "\n",
    "#check to see if insert many worked\n",
    "documents = db.awards.find()\n",
    "test_list =[]\n",
    "for document in documents:\n",
    "    test_list.append(document)\n",
    "db_awards_df = pd.DataFrame(test_list)\n",
    "\n",
    "# #This module takes all of our winning persons and randomly selects 100 unique authors for analysis. \n",
    "# import random\n",
    "\n",
    "# winners_unique = db_awards_df.loc[db_awards_df['achievement status'] == \"Winner\",['honoree name']].value_counts()\n",
    "\n",
    "# winner_list = []\n",
    "# while len(winner_list) < 100:\n",
    "#     random_index = random.randint(0,len(winners_unique)-1)\n",
    "#     winner = winners_unique.index[random_index][0]\n",
    "#     if winner in winner_list:\n",
    "#         continue\n",
    "#     else:\n",
    "#         winner_list.append(winner)\n",
    "\n",
    "\n",
    "# pd.DataFrame(winner_list).to_csv(\"C:/Users/JoshWeidenaar/Documents/Bootcamp/1_Homework/Project-2/listof100.csv\")\n",
    "\n",
    "db_awards_df[\"api_name\"] = [i.split(\"/\")[-1].replace(\"_\",\"%20\") for i in db_awards_df['wiki_url']]\n",
    "\n",
    "honoree_names = db_awards_df['api_name'].value_counts().index.tolist()\n",
    "\n",
    "# Wikiscrape Module\n",
    "\n",
    "\n",
    "listie_dicts = []\n",
    "for i in honoree_names:\n",
    "\n",
    "    WikiMedia_URL = f\"https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&ppprop=wikibase_item&titles={i}&formatversion=2&format=json\"\n",
    "    response = requests.get(WikiMedia_URL).json()\n",
    "    id_for_both = response['query']['pages'][0]\n",
    "    missing_key = 'missing'\n",
    "    found_key = 'pageprops'\n",
    "    honoree_dict = {}\n",
    "    honoree_dict['name'] = i\n",
    "    if found_key in id_for_both.keys():\n",
    "        found_ID = id_for_both['pageprops']['wikibase_item']\n",
    "        honoree_dict['id'] = found_ID\n",
    "    elif missing_key in id_for_both.keys():\n",
    "        missing_ID = id_for_both['missing']\n",
    "        honoree_dict['id'] = missing_ID\n",
    "    else: \n",
    "        print(f\"somethings wrong with {i}\")\n",
    "    listie_dicts.append(honoree_dict)\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(listie_dicts).loc[pd.DataFrame(listie_dicts)['id'] != True,]\n",
    "\n",
    "df = df.loc[pd.notna(df['id']),]\n",
    "\n",
    "Sex_ID = \"P21\"\n",
    "gender_possibilities = { \"Q6581072\" : 'Female',\n",
    " \"Q6581097\" : 'Male',\n",
    " \"Q1097630\" : 'Intersex',\n",
    " 'Q1052281' : 'Transgender_Female',\n",
    " 'Q2449503' : 'Transgender_Male'}\n",
    "\n",
    "input_possibilities = list(gender_possibilities.values())\n",
    "\n",
    "nums = [input_possibilities.index(i) for i in input_possibilities]\n",
    "\n",
    "text_forinput = \"0 == Female\\n\\n 1 == Male\\n\\n 2 == Intersex\\n\\n 3 == Transgender_Female\\n\\n 4 == Transgender_Male\"\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "author_gender_list = []\n",
    "for idx, i in enumerate(df['id']):\n",
    "    print(f\"author: {df['name'][idx]} \\n{(idx/len(df))*100}% of the way there\\n\\n\")\n",
    "    WikiData_URL = f\"https://m.wikidata.org/wiki/Special:EntityData/{i}.json\"\n",
    "    response = requests.get(WikiData_URL).json()\n",
    "    try:\n",
    "        property_verification = response['entities'][i]['claims'][Sex_ID][0]['mainsnak']['property']\n",
    "        gender_found = response['entities'][i]['claims'][Sex_ID][0]['mainsnak']['datavalue']['value']['id']\n",
    "\n",
    "        if gender_found in gender_possibilities.keys():\n",
    "            gender_found = gender_possibilities[gender_found]\n",
    "        else:\n",
    "            gender_found = \"NOTFOUND\"\n",
    "        author_gender_list.append(gender_found)\n",
    "    except KeyError:\n",
    "        print(f\"{i} prompted a KeyError \\n please enter gender assumed gender of {df['name'][idx]}\\n\\n\\n{text_forinput} \")\n",
    "        author_gender_list.append(input_possibilities[int(input())])\n",
    "\n",
    "    \n",
    "\n",
    "#change Jack Turner to MALE\n",
    "df['gender'] = author_gender_list\n",
    "\n",
    "df['matchname'] = [i.replace('%20',\" \") for i in df['name']]\n",
    "\n",
    "df_final = pd.merge(db_awards_df,df,how='left',left_on='honoree name',right_on='matchname')\n",
    "\n",
    "len(df_final.loc[pd.notnull(df_final['gender']),'honoree name'].value_counts())\n",
    "\n",
    "df_final.drop(axis=1,labels=['api_name','name','matchname','index'],inplace=True)\n",
    "\n",
    "df_final.to_json('Beard_db_final.json', default_handler=str,orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this is to run through all award not just books\n",
    "\n",
    "# Year_CodeBlock_awards = soup.find_all('div',class_=\"c-award-recipient\")\n",
    "\n",
    "# listie_dicts = []\n",
    "# for i in Year_CodeBlock_awards:\n",
    "#     plop = i.find_all('p')\n",
    "#     award = {}\n",
    "#     uid = i.get('data-award-template')\n",
    "#     award['award_type'] = uid\n",
    "#     award['length'] = len(plop)\n",
    "#     for count, j in enumerate(plop):\n",
    "#         key = cols_simple[count]\n",
    "#         award[key] = j.text.strip()\n",
    "#     listie_dicts.append(award)\n",
    "# allAward_df = pd.DataFrame(listie_dicts)\n",
    "# types = df['award_type'].unique().tolist()\n",
    "\n",
    "# #this finds all award types and makes a dictonary of award types as keys and values as lists of tags officially a \"bs4.element.ResultSet\" \n",
    "# # IT IS NOT CONNECTED TO anything but the last soup object\n",
    "\n",
    "# #ONE LINE DOWN IS HOW TYPES WAS ORIGINALLY GRABBED, I BELIEVE BS4 can probably do this more efficiently\n",
    "# #types = df['award_type'].unique().tolist()\n",
    "\n",
    "# dictie = {}\n",
    "# for i in types:\n",
    "#     key = i\n",
    "#     dictie[key] = soup.find_all(attrs={\"data-award-template\":i})\n",
    "\n",
    "# listie_dicts = []\n",
    "# for i in dictie:\n",
    "#     for j in dictie[i]:\n",
    "#         plop = j.find_all('p')\n",
    "#         award = {}\n",
    "#         award['award_type'] = uid\n",
    "#         award['length'] = len(plop)\n",
    "#         for count, v in enumerate(plop):\n",
    "#             key = cols_simple[count]\n",
    "#             award[key] = v.text.strip()\n",
    "#         listie_dicts.append(award)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterates through single year awards and pulls out 1 single award\n",
    "# 9 keys in dict, first is \"tag\" which identifies the div tags \"data-award-template\" value (this is in the first loop), \n",
    "#then it goes into the second loop and enters in the remaining 8 data points\n",
    "#this is now the initial nested loop, this also checks for length issues, suggest currently, reviewing and then redoing according to \"UID\" variable rules.\n",
    "##V1\n",
    "# listie_dicts = []\n",
    "# for i in Year_CodeBlock_awards:\n",
    "#     listie_dicts.append(award)\n",
    "#     plop = i.find_all('p')\n",
    "#     award = {}\n",
    "#     uid = i.get('data-award-template')\n",
    "#     award['award_type'] = uid\n",
    "#     for count, j in enumerate(plop):\n",
    "#         key = cols_simple[count]\n",
    "#         if len(plop) != 8:\n",
    "#             award[\"lengthofissue\"] = len(plop)\n",
    "#             award[key] = j.text.strip()\n",
    "# #         if len(plop) == 7 & count == 4:\n",
    "            \n",
    "# # #             print(f\"THIS AWARD IS MISSING SOME INFORMATION\\n\\nTHE AWARD CODE BLOCK:\\n\\n{i}\\n\\n\\n\\n\\n \\nWHAT IS THE KEY THAT IS MISSING? \\n\\n\\n\\n\\n THE AVAILABLE KEYS \\n{cols_simple}\") \n",
    "# # #             key = input()\n",
    "# # #             print(f\"\\n\\nTHE AWARD CODE BLOCK:\\n\\n{i}\\n\\n\\n\\n\\n PLEASE ENTER THE VALUE YOU WOULD LIKE STORED FOR THE MISSING VARIABLE\")\n",
    "# #               award[key] = np.nan\n",
    "# #               award[\"lengthofissue\"] = len(plop)\n",
    "# #         elif len(plop) == 6 & count == 4:\n",
    "#         else:\n",
    "#             award[key] = j.text.strip() \n",
    "            \n",
    "# df = pd.DataFrame(listie_dicts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##V2\n",
    "# listie_dicts = []\n",
    "# for i in Year_CodeBlock_awards:\n",
    "#     plop = i.find_all('p')\n",
    "#     award = {}\n",
    "#     uid = i.get('data-award-template')\n",
    "#     award['award_type'] = uid\n",
    "#     award['length'] = len(plop)\n",
    "#     for count, j in enumerate(plop):\n",
    "#         key = cols_simple[count]\n",
    "#         if (uid == \"components.search-results.award.rnc.restaurant\") & (count == 3):\n",
    "#             award[key] = np.nan\n",
    "# #         elif (uid == \"components.search-results.award.rnc.humanitarian\") & (count == 3 | 4):\n",
    "# #             award[key] = np.nan\n",
    "# #             award[\"length\"] = len(plop)\n",
    "#         else:\n",
    "#             award[key] = j.text.strip()\n",
    "#     listie_dicts.append(award)\n",
    "# df2 = pd.DataFrame(listie_dicts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##V3\n",
    "# listie_dicts = []\n",
    "# for i in Year_CodeBlock_awards:\n",
    "#     plop = i.find_all('p')\n",
    "#     award = {}\n",
    "#     uid = i.get('data-award-template')\n",
    "#     award['award_type'] = uid\n",
    "#     length = len(plop)\n",
    "#     award['length'] = len(plop)\n",
    "    \n",
    "#     if length == 8:\n",
    "        \n",
    "#         for count, j in enumerate(plop):\n",
    "            \n",
    "#             key = cols_simple[count]\n",
    "#             award[key] = j.text.strip()\n",
    "            \n",
    "#     elif uid == \"components.search-results.award.rnc.restaurant\":\n",
    "        \n",
    "#         for count, j in enumerate(plop):\n",
    "            \n",
    "#             key = cols_simple[count]\n",
    "#             alphastep = cols_simple[count + 1]\n",
    "            \n",
    "#             if (count == 3):\n",
    "                \n",
    "#                 award[key] = np.nan\n",
    "#                 award[alphastep] = j.text.strip()\n",
    "                \n",
    "#             elif (count > 3):\n",
    "                \n",
    "#                 award[alphastep] = j.text.strip()\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 award[key] = j.text.strip()\n",
    "#     elif uid == \"components.search-results.award.rnc.whos-who\":\n",
    "        \n",
    "#         for i in range(8):\n",
    "            \n",
    "#             if i < len(plop):\n",
    "#                 key = cols_simple[i]\n",
    "#                 alphastep = cols_simple[i + 1]\n",
    "#                 omegastep = cols_simple[i +2]\n",
    "#                 negastep = cols_simple[i-1]\n",
    "#                 if key == 'name of work/effort':\n",
    "#                     award[key] = np.nan\n",
    "#                     award[alphastep] = plop[i].text.strip()\n",
    "#                     print(plop[i])\n",
    "#                     print(alphastep)\n",
    "#                 elif key == 'type of work':\n",
    "#                     award[key] = np.nan\n",
    "#                     award[alphastep] = plop[i - 1].text.strip()\n",
    "#                     award[omegastep] = plop[i].text.strip()\n",
    "#                     print(plop[i-1])\n",
    "#                 else:\n",
    "#                     award[key] = plop[i].text.strip()\n",
    "                #award[key] = plop[i].text.strip()\n",
    "#             key = cols_simple[count]\n",
    "#             alphastep = cols_simple[count + 1]\n",
    "#             omegastep = cols_simple[count + 2]\n",
    "#             if (count == 3):\n",
    "#                 award[key] = np.nan\n",
    "#                 award[alphastep] = j.text.strip()\n",
    "#                 award[omegastep] = 'ohno'\n",
    "\n",
    "#             elif (count == 5):\n",
    "                \n",
    "#                 award[alphastep] = j.text.strip()\n",
    "\n",
    "#             else:\n",
    "#                 award[key] = j.text.strip()\n",
    "                \n",
    "#     listie_dicts.append(award)\n",
    "# ddd = pd.DataFrame(listie_dicts)\n",
    "# ddd.loc[ddd['award_type'] == \"components.search-results.award.rnc.whos-who\",]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
